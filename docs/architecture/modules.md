## **Modules dÃ©taillÃ©s**  
Nous allons dÃ©tailler chaque **composant clÃ©** du projet **GestureMouseApp**.  

### ğŸ“‚ **1ï¸âƒ£ DÃ©tection des gestes (`modules/gesture_detection.md`)**  
Ce module gÃ¨re **la capture vidÃ©o et lâ€™analyse des mains** avec **MediaPipe**.  

âœ” **DÃ©tecte les landmarks des mains** en temps rÃ©el  
âœ” **PrÃ©cision optimisÃ©e avec filtrage et stabilisation**  
âœ” **Envoie les donnÃ©es aux modules de reconnaissance et contrÃ´le**  

```python
# Extrait de gesture_detection.py
import mediapipe as mp

class GestureDetector:
    def __init__(self):
        self.hands = mp.solutions.hands.Hands()

    def process_frame(self, frame):
        results = self.hands.process(frame)
        return results.multi_hand_landmarks
```
ğŸ’¡ **Ce module est essentiel pour tous les projets nÃ©cessitant la reconnaissance des mains !**  

---

### ğŸ“‚ **2ï¸âƒ£ Reconnaissance des mains (`modules/hand_recognition.md`)**  
Ce module **interprÃ¨te les gestes en fonction des positions des doigts**.  

âœ” **Encodage binaire pour chaque doigt** ğŸ–ï¸  
âœ” **Classification des gestes** (V-GEST, PINCH, FISTâ€¦)  
âœ” **Utilisation dâ€™une main dominante pour affiner la dÃ©tection**  

```python
class HandRecognizer:
    def set_finger_state(self):
        self.fingers = [1 if tip.y < pip.y else 0 for tip, pip in self.finger_positions]
```
ğŸ’¡ **Modulable, ce systÃ¨me peut Ãªtre rÃ©utilisÃ© pour dâ€™autres applications interactives** !  

---

### ğŸ“‚ **3ï¸âƒ£ ContrÃ´le des actions (`modules/gesture_controller.md`)**  
Ce module **exÃ©cute les actions en fonction des gestes dÃ©tectÃ©s**.  

âœ” **Interaction avec le systÃ¨me** (clics, dÃ©filement, volumeâ€¦)  
âœ” **Gestion dynamique de la vitesse et prÃ©cision du curseur**  
âœ” **ContrÃ´le intelligent pour Ã©viter les erreurs de reconnaissance**  

```python
import pyautogui

class GestureController:
    def handle_gesture(self, gesture_name):
        if gesture_name == "V_GEST":
            pyautogui.moveTo(500, 300)
        elif gesture_name == "PINCH_MAJOR":
            pyautogui.press("volume_up")
```
ğŸ’¡ **Ce module transforme la dÃ©tection de gestes en une interaction rÃ©elle avec lâ€™ordinateur !**  

---
Voici le **diagramme de sÃ©quence** illustrant le fonctionnement gÃ©nÃ©ral de **GestureMouseApp**, depuis la capture vidÃ©o jusquâ€™Ã  lâ€™exÃ©cution des actions du systÃ¨me.  

```mermaid
sequenceDiagram
    participant Utilisateur
    participant Camera
    participant GestureDetector
    participant HandRecognizer
    participant GestureController
    participant SystemActions

    Utilisateur->>Camera: Effectue un geste
    Camera->>GestureDetector: Capture le flux vidÃ©o
    GestureDetector->>HandRecognizer: Analyse les landmarks
    HandRecognizer->>GestureController: InterprÃ¨te le geste
    GestureController->>SystemActions: ExÃ©cute l'action correspondante
    SystemActions->>Utilisateur: RÃ©sultat (dÃ©placement du curseur, clic...)

```

âœ” **Capture vidÃ©o en temps rÃ©el** ğŸ¥  
âœ” **DÃ©tection des landmarks avec MediaPipe** âœ‹  
âœ” **InterprÃ©tation du geste et envoi de commandes** ğŸ–±ï¸  
âœ” **ExÃ©cution des actions systÃ¨me** (clic, dÃ©filement, rÃ©glage du volume)  

